{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OuqAIcTJjqw"
   },
   "source": [
    "<h1 align=center> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;应用系统体系架构 - 人工智能模块 </h1>\n",
    "\n",
    "<h1 align=center> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A2：卷积神经网络 - 作业</h1>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "### 关于这个Notebook\n",
    "\n",
    "在这个Notebook中，大家参照上课的CIFAR-10的案例，构建卷积神经网络来对CIFAR-100数据集中的图像进行分类，并且确保分类准确率可以超过45%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTCI1oaSJjqz"
   },
   "source": [
    "### 构建对CIFAR-100数据集中的图像进行分类的CNN\n",
    "\n",
    "有关 CIFAR-100 的详细内容可以参阅：\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "\n",
    "### 构建卷积神经网络(Convolutional Neural Nets)\n",
    "<font color=red>作业要求：</font>\n",
    "\n",
    "- <font color=red>你可以使用Keras来构建和训练自己的卷积神经网络，并通过调整超参数使你的模型的分类准确率可以达到45%以上。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypYf3KCSJjq0"
   },
   "source": [
    "下面是导入必要的包、加载数据和进行数据预处理的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1734633555732,
     "user": {
      "displayName": "ALEX KING",
      "userId": "08416762131815811002"
     },
     "user_tz": -480
    },
    "id": "Kv1x1YMPJjq0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar100\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22439,
     "status": "ok",
     "timestamp": 1734633578600,
     "user": {
      "displayName": "ALEX KING",
      "userId": "08416762131815811002"
     },
     "user_tz": -480
    },
    "id": "DCBB5qUlJjq2",
    "outputId": "cb38f0cf-4533-4255-fa8b-d4b238d70213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1734633578600,
     "user": {
      "displayName": "ALEX KING",
      "userId": "08416762131815811002"
     },
     "user_tz": -480
    },
    "id": "KHy0UTufJjq3",
    "outputId": "561c3522-1de6-458a-b928-0a410b3eed55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "      .ndarray_repr .ndarray_raw_data {\n",
       "        display: none;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_raw_data {\n",
       "        display: block;\n",
       "      }\n",
       "      .ndarray_repr.show_array .ndarray_image_preview {\n",
       "        display: none;\n",
       "      }\n",
       "      </style>\n",
       "      <div id=\"id-71a9533c-10cf-4016-a824-f6c9389f5ab4\" class=\"ndarray_repr\"><pre>ndarray (32, 32, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[ 92,  73,  46],\n",
       "        [ 96,  73,  44],\n",
       "        [ 96,  69,  40],\n",
       "        ...,\n",
       "        [134, 100,  55],\n",
       "        [136, 101,  57],\n",
       "        [139, 105,  61]],\n",
       "\n",
       "       [[ 94,  75,  47],\n",
       "        [ 95,  71,  42],\n",
       "        [ 97,  70,  41],\n",
       "        ...,\n",
       "        [135, 101,  56],\n",
       "        [136, 101,  56],\n",
       "        [145, 110,  65]],\n",
       "\n",
       "       [[ 97,  78,  52],\n",
       "        [ 93,  71,  43],\n",
       "        [101,  74,  46],\n",
       "        ...,\n",
       "        [129,  95,  54],\n",
       "        [136, 102,  57],\n",
       "        [143, 109,  64]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[157, 123,  85],\n",
       "        [203, 184, 152],\n",
       "        [209, 185, 134],\n",
       "        ...,\n",
       "        [164, 131,  85],\n",
       "        [158, 122,  72],\n",
       "        [173, 140,  97]],\n",
       "\n",
       "       [[160, 129,  89],\n",
       "        [172, 148, 122],\n",
       "        [188, 162, 119],\n",
       "        ...,\n",
       "        [165, 132,  86],\n",
       "        [167, 131,  81],\n",
       "        [182, 149, 106]],\n",
       "\n",
       "       [[166, 138,  99],\n",
       "        [157, 130,  97],\n",
       "        [152, 121,  82],\n",
       "        ...,\n",
       "        [159, 128,  82],\n",
       "        [173, 136,  91],\n",
       "        [180, 143, 100]]], dtype=uint8)</pre></div><script>\n",
       "      (() => {\n",
       "      const titles = ['show data', 'hide data'];\n",
       "      let index = 0\n",
       "      document.querySelector('#id-71a9533c-10cf-4016-a824-f6c9389f5ab4 button').onclick = (e) => {\n",
       "        document.querySelector('#id-71a9533c-10cf-4016-a824-f6c9389f5ab4').classList.toggle('show_array');\n",
       "        index = (++index) % 2;\n",
       "        document.querySelector('#id-71a9533c-10cf-4016-a824-f6c9389f5ab4 button').textContent = titles[index];\n",
       "        e.preventDefault();\n",
       "        e.stopPropagation();\n",
       "      }\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "array([[[ 92,  73,  46],\n",
       "        [ 96,  73,  44],\n",
       "        [ 96,  69,  40],\n",
       "        ...,\n",
       "        [134, 100,  55],\n",
       "        [136, 101,  57],\n",
       "        [139, 105,  61]],\n",
       "\n",
       "       [[ 94,  75,  47],\n",
       "        [ 95,  71,  42],\n",
       "        [ 97,  70,  41],\n",
       "        ...,\n",
       "        [135, 101,  56],\n",
       "        [136, 101,  56],\n",
       "        [145, 110,  65]],\n",
       "\n",
       "       [[ 97,  78,  52],\n",
       "        [ 93,  71,  43],\n",
       "        [101,  74,  46],\n",
       "        ...,\n",
       "        [129,  95,  54],\n",
       "        [136, 102,  57],\n",
       "        [143, 109,  64]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[157, 123,  85],\n",
       "        [203, 184, 152],\n",
       "        [209, 185, 134],\n",
       "        ...,\n",
       "        [164, 131,  85],\n",
       "        [158, 122,  72],\n",
       "        [173, 140,  97]],\n",
       "\n",
       "       [[160, 129,  89],\n",
       "        [172, 148, 122],\n",
       "        [188, 162, 119],\n",
       "        ...,\n",
       "        [165, 132,  86],\n",
       "        [167, 131,  81],\n",
       "        [182, 149, 106]],\n",
       "\n",
       "       [[166, 138,  99],\n",
       "        [157, 130,  97],\n",
       "        [152, 121,  82],\n",
       "        ...,\n",
       "        [159, 128,  82],\n",
       "        [173, 136,  91],\n",
       "        [180, 143, 100]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Each image is a 32 x 32 x 3 numpy array\n",
    "x_train[444].shape\n",
    "x_train[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1734633578600,
     "user": {
      "displayName": "ALEX KING",
      "userId": "08416762131815811002"
     },
     "user_tz": -480
    },
    "id": "DdtciumEJjq4",
    "outputId": "9fb8b09a-982e-4d4f-beb6-e7ee6bbdd70d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's look at one of the images\n",
    "\n",
    "print(y_train[444])\n",
    "plt.imshow(x_train[444]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1734633578909,
     "user": {
      "displayName": "ALEX KING",
      "userId": "08416762131815811002"
     },
     "user_tz": -480
    },
    "id": "2mtY5YANJjq4"
   },
   "outputs": [],
   "source": [
    "num_classes = 100\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734633578909,
     "user": {
      "displayName": "ALEX KING",
      "userId": "08416762131815811002"
     },
     "user_tz": -480
    },
    "id": "pq1uGf2WJjq4",
    "outputId": "d5015e20-20ee-476a-bcdf-a4915991869d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position\n",
    "y_train[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734633578909,
     "user": {
      "displayName": "ALEX KING",
      "userId": "08416762131815811002"
     },
     "user_tz": -480
    },
    "id": "wEztq_J3Jjq5"
   },
   "outputs": [],
   "source": [
    "# As before, let's make everything float and scale\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PF4B83bdJjq5"
   },
   "source": [
    "## Keras 中用于 CNN 的层\n",
    "- 之前我们使用过基础的 Dense、Activation 和 Dropout 层构建过神经网络。\n",
    "\n",
    "- 现在我们将描述如何使用Keras中提供的与CNN相关的一些层。\n",
    "\n",
    "### Conv2D\n",
    "\n",
    "```python\n",
    "keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
    "```\n",
    "\n",
    "其中若干个参数的含义：\n",
    "- `filters`: 每个位置使用的过滤器数量，换句话说，就是输出的深度。\n",
    "- `kernel_size`: 一个 (x,y) 元素，给出了要使用的卷积核的高度和宽度。\n",
    "- `strides`: 一个 (x,y) 元素，给出了在每一维上的步幅。默认值为 `(1,1)`\n",
    "- `input_shape`: 只有第一层需要这个参数，表示输入的形状。\n",
    "\n",
    "注意，输出的尺寸是由 kernel_size 和 strides 确定的。\n",
    "\n",
    "### MaxPooling2D\n",
    "`keras.layers.pooling.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)`\n",
    "\n",
    "- `pool_size`: 要池化的网格的 (x,y) 尺寸。\n",
    "- `strides`: 假设等于 `pool_size` ，除非另外做了设定。\n",
    "\n",
    "### Flatten\n",
    "将其输入转换为一维向量。通常用于从卷积层转移到全连接层时。\n",
    "\n",
    "---\n",
    "\n",
    "## <font color=red> 构建你的CNN </font>\n",
    "<font color=red> 下面看你的了，构建你自己的模型并进行训练。</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 12714043,
     "status": "ok",
     "timestamp": 1734646292948,
     "user": {
      "displayName": "ALEX KING",
      "userId": "08416762131815811002"
     },
     "user_tz": -480
    },
    "id": "_c-TOw_AJjq5",
    "outputId": "729ae7b1-5b73-4a86-b261-399edbaeb910"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,500</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m7,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │         \u001b[38;5;34m102,500\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,795,556</span> (60.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,795,556\u001b[0m (60.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,786,340</span> (60.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,786,340\u001b[0m (60.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,216</span> (36.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,216\u001b[0m (36.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 127ms/step - accuracy: 0.0767 - loss: 4.1900 - val_accuracy: 0.1088 - val_loss: 4.1035\n",
      "Epoch 2/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 119ms/step - accuracy: 0.2638 - loss: 2.9215 - val_accuracy: 0.2513 - val_loss: 3.1788\n",
      "Epoch 3/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 120ms/step - accuracy: 0.3974 - loss: 2.2732 - val_accuracy: 0.3600 - val_loss: 2.4388\n",
      "Epoch 4/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 117ms/step - accuracy: 0.4802 - loss: 1.9152 - val_accuracy: 0.3335 - val_loss: 2.7275\n",
      "Epoch 5/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 116ms/step - accuracy: 0.5430 - loss: 1.6548 - val_accuracy: 0.3837 - val_loss: 2.4576\n",
      "Epoch 6/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 120ms/step - accuracy: 0.5931 - loss: 1.4426 - val_accuracy: 0.3910 - val_loss: 2.5351\n",
      "Epoch 7/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 116ms/step - accuracy: 0.6389 - loss: 1.2675 - val_accuracy: 0.5107 - val_loss: 1.8445\n",
      "Epoch 8/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 120ms/step - accuracy: 0.6736 - loss: 1.1172 - val_accuracy: 0.5153 - val_loss: 1.8651\n",
      "Epoch 9/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 120ms/step - accuracy: 0.7149 - loss: 0.9600 - val_accuracy: 0.4189 - val_loss: 2.6578\n",
      "Epoch 10/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 119ms/step - accuracy: 0.7520 - loss: 0.8307 - val_accuracy: 0.5406 - val_loss: 1.8266\n",
      "Epoch 11/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 123ms/step - accuracy: 0.7860 - loss: 0.7088 - val_accuracy: 0.5056 - val_loss: 2.0625\n",
      "Epoch 12/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 120ms/step - accuracy: 0.8150 - loss: 0.6122 - val_accuracy: 0.5328 - val_loss: 1.9757\n",
      "Epoch 13/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 120ms/step - accuracy: 0.8426 - loss: 0.5073 - val_accuracy: 0.5363 - val_loss: 2.0126\n",
      "Epoch 14/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.8669 - loss: 0.4325 - val_accuracy: 0.4881 - val_loss: 2.2394\n",
      "Epoch 15/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 120ms/step - accuracy: 0.8846 - loss: 0.3681 - val_accuracy: 0.5579 - val_loss: 1.9354\n",
      "Epoch 16/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 120ms/step - accuracy: 0.8981 - loss: 0.3221 - val_accuracy: 0.5591 - val_loss: 1.9761\n",
      "Epoch 17/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 123ms/step - accuracy: 0.9118 - loss: 0.2747 - val_accuracy: 0.5849 - val_loss: 1.9919\n",
      "Epoch 18/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9234 - loss: 0.2398 - val_accuracy: 0.5588 - val_loss: 2.1547\n",
      "Epoch 19/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 120ms/step - accuracy: 0.9350 - loss: 0.2074 - val_accuracy: 0.5826 - val_loss: 1.9220\n",
      "Epoch 20/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 120ms/step - accuracy: 0.9435 - loss: 0.1804 - val_accuracy: 0.5676 - val_loss: 2.2315\n",
      "Epoch 21/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 120ms/step - accuracy: 0.9442 - loss: 0.1768 - val_accuracy: 0.5411 - val_loss: 2.3647\n",
      "Epoch 22/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 120ms/step - accuracy: 0.9474 - loss: 0.1651 - val_accuracy: 0.6133 - val_loss: 2.0178\n",
      "Epoch 23/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 123ms/step - accuracy: 0.9532 - loss: 0.1467 - val_accuracy: 0.6092 - val_loss: 2.0229\n",
      "Epoch 24/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 120ms/step - accuracy: 0.9585 - loss: 0.1288 - val_accuracy: 0.5909 - val_loss: 2.1841\n",
      "Epoch 25/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 120ms/step - accuracy: 0.9607 - loss: 0.1221 - val_accuracy: 0.6094 - val_loss: 2.0847\n",
      "Epoch 26/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9610 - loss: 0.1205 - val_accuracy: 0.5976 - val_loss: 2.1719\n",
      "Epoch 27/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 123ms/step - accuracy: 0.9694 - loss: 0.1000 - val_accuracy: 0.5895 - val_loss: 2.2390\n",
      "Epoch 28/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9707 - loss: 0.0956 - val_accuracy: 0.6209 - val_loss: 2.1091\n",
      "Epoch 29/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 119ms/step - accuracy: 0.9726 - loss: 0.0871 - val_accuracy: 0.6116 - val_loss: 2.1018\n",
      "Epoch 30/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9722 - loss: 0.0881 - val_accuracy: 0.6015 - val_loss: 2.3280\n",
      "Epoch 31/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9719 - loss: 0.0872 - val_accuracy: 0.6243 - val_loss: 2.1878\n",
      "Epoch 32/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9750 - loss: 0.0829 - val_accuracy: 0.6121 - val_loss: 2.1800\n",
      "Epoch 33/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9773 - loss: 0.0719 - val_accuracy: 0.5921 - val_loss: 2.2329\n",
      "Epoch 34/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9779 - loss: 0.0708 - val_accuracy: 0.5938 - val_loss: 2.4979\n",
      "Epoch 35/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9800 - loss: 0.0675 - val_accuracy: 0.6086 - val_loss: 2.3124\n",
      "Epoch 36/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9797 - loss: 0.0669 - val_accuracy: 0.6176 - val_loss: 2.2488\n",
      "Epoch 37/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9786 - loss: 0.0694 - val_accuracy: 0.6326 - val_loss: 2.1131\n",
      "Epoch 38/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9812 - loss: 0.0598 - val_accuracy: 0.5591 - val_loss: 2.5763\n",
      "Epoch 39/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9819 - loss: 0.0625 - val_accuracy: 0.6115 - val_loss: 2.1915\n",
      "Epoch 40/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9815 - loss: 0.0578 - val_accuracy: 0.6274 - val_loss: 2.1701\n",
      "Epoch 41/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 120ms/step - accuracy: 0.9830 - loss: 0.0525 - val_accuracy: 0.6331 - val_loss: 2.2228\n",
      "Epoch 42/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 120ms/step - accuracy: 0.9846 - loss: 0.0492 - val_accuracy: 0.6314 - val_loss: 2.1750\n",
      "Epoch 43/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9849 - loss: 0.0480 - val_accuracy: 0.6188 - val_loss: 2.2125\n",
      "Epoch 44/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9840 - loss: 0.0500 - val_accuracy: 0.5553 - val_loss: 2.8010\n",
      "Epoch 45/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 120ms/step - accuracy: 0.9855 - loss: 0.0466 - val_accuracy: 0.6196 - val_loss: 2.3514\n",
      "Epoch 46/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9850 - loss: 0.0493 - val_accuracy: 0.6322 - val_loss: 2.2261\n",
      "Epoch 47/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9877 - loss: 0.0418 - val_accuracy: 0.6441 - val_loss: 2.2096\n",
      "Epoch 48/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 120ms/step - accuracy: 0.9869 - loss: 0.0429 - val_accuracy: 0.6233 - val_loss: 2.3620\n",
      "Epoch 49/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9866 - loss: 0.0427 - val_accuracy: 0.6299 - val_loss: 2.3658\n",
      "Epoch 50/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9891 - loss: 0.0356 - val_accuracy: 0.6192 - val_loss: 2.5311\n",
      "Epoch 51/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9870 - loss: 0.0413 - val_accuracy: 0.6286 - val_loss: 2.2986\n",
      "Epoch 52/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9893 - loss: 0.0368 - val_accuracy: 0.6241 - val_loss: 2.2199\n",
      "Epoch 53/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9889 - loss: 0.0349 - val_accuracy: 0.6352 - val_loss: 2.3077\n",
      "Epoch 54/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9884 - loss: 0.0386 - val_accuracy: 0.6257 - val_loss: 2.3978\n",
      "Epoch 55/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9888 - loss: 0.0343 - val_accuracy: 0.6265 - val_loss: 2.3130\n",
      "Epoch 56/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9888 - loss: 0.0349 - val_accuracy: 0.6347 - val_loss: 2.2249\n",
      "Epoch 57/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 119ms/step - accuracy: 0.9899 - loss: 0.0305 - val_accuracy: 0.6366 - val_loss: 2.3258\n",
      "Epoch 58/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9903 - loss: 0.0322 - val_accuracy: 0.6151 - val_loss: 2.4876\n",
      "Epoch 59/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 120ms/step - accuracy: 0.9896 - loss: 0.0331 - val_accuracy: 0.6353 - val_loss: 2.3575\n",
      "Epoch 60/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9910 - loss: 0.0289 - val_accuracy: 0.6297 - val_loss: 2.4274\n",
      "Epoch 61/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9909 - loss: 0.0287 - val_accuracy: 0.6214 - val_loss: 2.4278\n",
      "Epoch 62/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9910 - loss: 0.0279 - val_accuracy: 0.6390 - val_loss: 2.4167\n",
      "Epoch 63/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9914 - loss: 0.0296 - val_accuracy: 0.6255 - val_loss: 2.2982\n",
      "Epoch 64/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9898 - loss: 0.0305 - val_accuracy: 0.6419 - val_loss: 2.3644\n",
      "Epoch 65/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 122ms/step - accuracy: 0.9904 - loss: 0.0294 - val_accuracy: 0.6187 - val_loss: 2.4131\n",
      "Epoch 66/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 119ms/step - accuracy: 0.9924 - loss: 0.0254 - val_accuracy: 0.6257 - val_loss: 2.3620\n",
      "Epoch 67/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9920 - loss: 0.0261 - val_accuracy: 0.6292 - val_loss: 2.4180\n",
      "Epoch 68/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 119ms/step - accuracy: 0.9913 - loss: 0.0279 - val_accuracy: 0.6098 - val_loss: 2.7756\n",
      "Epoch 69/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9915 - loss: 0.0257 - val_accuracy: 0.6257 - val_loss: 2.5091\n",
      "Epoch 70/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 119ms/step - accuracy: 0.9908 - loss: 0.0287 - val_accuracy: 0.6296 - val_loss: 2.5924\n",
      "Epoch 71/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 120ms/step - accuracy: 0.9924 - loss: 0.0250 - val_accuracy: 0.6418 - val_loss: 2.4819\n",
      "Epoch 72/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 120ms/step - accuracy: 0.9932 - loss: 0.0236 - val_accuracy: 0.6359 - val_loss: 2.5979\n",
      "Epoch 73/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 120ms/step - accuracy: 0.9931 - loss: 0.0223 - val_accuracy: 0.6419 - val_loss: 2.5708\n",
      "Epoch 74/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9936 - loss: 0.0216 - val_accuracy: 0.6297 - val_loss: 2.5764\n",
      "Epoch 75/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 124ms/step - accuracy: 0.9930 - loss: 0.0231 - val_accuracy: 0.6410 - val_loss: 2.4308\n",
      "Epoch 76/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 124ms/step - accuracy: 0.9936 - loss: 0.0216 - val_accuracy: 0.6398 - val_loss: 2.4616\n",
      "Epoch 77/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 120ms/step - accuracy: 0.9938 - loss: 0.0208 - val_accuracy: 0.6434 - val_loss: 2.5201\n",
      "Epoch 78/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 123ms/step - accuracy: 0.9936 - loss: 0.0224 - val_accuracy: 0.5981 - val_loss: 2.6938\n",
      "Epoch 79/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 123ms/step - accuracy: 0.9926 - loss: 0.0237 - val_accuracy: 0.6384 - val_loss: 2.4038\n",
      "Epoch 80/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 120ms/step - accuracy: 0.9922 - loss: 0.0243 - val_accuracy: 0.6473 - val_loss: 2.3555\n",
      "Epoch 81/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 120ms/step - accuracy: 0.9931 - loss: 0.0224 - val_accuracy: 0.6345 - val_loss: 2.4124\n",
      "Epoch 82/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 124ms/step - accuracy: 0.9945 - loss: 0.0180 - val_accuracy: 0.6453 - val_loss: 2.4644\n",
      "Epoch 83/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 120ms/step - accuracy: 0.9943 - loss: 0.0173 - val_accuracy: 0.6203 - val_loss: 2.5227\n",
      "Epoch 84/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9943 - loss: 0.0175 - val_accuracy: 0.6342 - val_loss: 2.5008\n",
      "Epoch 85/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 120ms/step - accuracy: 0.9939 - loss: 0.0187 - val_accuracy: 0.6430 - val_loss: 2.5239\n",
      "Epoch 86/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 123ms/step - accuracy: 0.9941 - loss: 0.0182 - val_accuracy: 0.6426 - val_loss: 2.4670\n",
      "Epoch 87/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 122ms/step - accuracy: 0.9948 - loss: 0.0178 - val_accuracy: 0.6393 - val_loss: 2.5166\n",
      "Epoch 88/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 119ms/step - accuracy: 0.9930 - loss: 0.0210 - val_accuracy: 0.6472 - val_loss: 2.4087\n",
      "Epoch 89/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9946 - loss: 0.0193 - val_accuracy: 0.6336 - val_loss: 2.5988\n",
      "Epoch 90/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9926 - loss: 0.0230 - val_accuracy: 0.6467 - val_loss: 2.4266\n",
      "Epoch 91/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9942 - loss: 0.0180 - val_accuracy: 0.6310 - val_loss: 2.4962\n",
      "Epoch 92/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9938 - loss: 0.0207 - val_accuracy: 0.6438 - val_loss: 2.5633\n",
      "Epoch 93/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9944 - loss: 0.0166 - val_accuracy: 0.6432 - val_loss: 2.5977\n",
      "Epoch 94/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 120ms/step - accuracy: 0.9948 - loss: 0.0171 - val_accuracy: 0.6447 - val_loss: 2.5532\n",
      "Epoch 95/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9934 - loss: 0.0202 - val_accuracy: 0.6352 - val_loss: 2.5330\n",
      "Epoch 96/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 123ms/step - accuracy: 0.9941 - loss: 0.0184 - val_accuracy: 0.6320 - val_loss: 2.6168\n",
      "Epoch 97/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 119ms/step - accuracy: 0.9946 - loss: 0.0174 - val_accuracy: 0.6308 - val_loss: 2.7423\n",
      "Epoch 98/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 119ms/step - accuracy: 0.9949 - loss: 0.0156 - val_accuracy: 0.6420 - val_loss: 2.5480\n",
      "Epoch 99/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 119ms/step - accuracy: 0.9948 - loss: 0.0154 - val_accuracy: 0.6330 - val_loss: 2.4644\n",
      "Epoch 100/100\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 123ms/step - accuracy: 0.9942 - loss: 0.0195 - val_accuracy: 0.6322 - val_loss: 2.6369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c04fdcea740>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "\n",
    "# 定义模型\n",
    "model = Sequential()\n",
    "\n",
    "# 卷积模块1\n",
    "model.add(Conv2D(256, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 卷积模块2\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 卷积模块3\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 卷积模块4\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(512,(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# 全连接层\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization(momentum=0.95,\n",
    "        epsilon=0.005,\n",
    "        beta_initializer=RandomNormal(mean=0.0, stddev=0.05),\n",
    "        gamma_initializer=Constant(value=0.9)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# 编译模型\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# 打印模型结构\n",
    "model.summary()\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=64,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKw8snquJjq6"
   },
   "source": [
    "使用测试数据集验证你的模型的准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10548,
     "status": "ok",
     "timestamp": 1734646303466,
     "user": {
      "displayName": "ALEX KING",
      "userId": "08416762131815811002"
     },
     "user_tz": -480
    },
    "id": "2ML7_j2QJjq6",
    "outputId": "35734dc6-4d21-4497-95ad-af7ed51e807f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.6368753910064697\n",
      "Test accuracy: 0.6322000026702881\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
